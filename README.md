# ğŸ§  Rock-Paper-Scissors Hand Gesture Classification with CNN

This project uses a **Convolutional Neural Network (CNN)** to classify hand gestures for the game **Rock-Paper-Scissors**. The model takes images of hand gestures as input and predicts whether the gesture represents **rock**, **paper**, or **scissors**.

## ğŸ“Œ Project Overview

The goal is to build a deep learning model that can accurately recognize the three hand gestures using image data. By training a CNN on labeled gesture images, the model learns to extract visual features and patterns that differentiate each class.

## ğŸ–¼ï¸ Input & Output

- **Input:** Image of a hand showing one of the gestures (rock, paper, or scissors)
- **Output:** Predicted class label â€“ `Rock`, `Paper`, or `Scissors`

## ğŸ“‚ Dataset

You can download the Dataset of this project from the link :
- [Rock-Paper-Scissors Dataset from TensorFlow Datasets](https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip)
- Or create a custom dataset using your own gesture images
